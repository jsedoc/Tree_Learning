{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from queue import *\n",
    "\n",
    "from Tree2TreeDataLoaderRelabel import *\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(n_iters,train_filename,target_filename):\n",
    "    data_loader = Tree2TreeDataLoader(train_filename,target_filename)\n",
    "    training_data = data_loader.get_data()\n",
    "    print(len(training_data))\n",
    "    training_pairs = [(random.choice(training_data))\n",
    "                      for i in range(n_iters)]\n",
    "    print(training_pairs[0])\n",
    "    print(training_pairs[0][1].key)\n",
    "    return training_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_avg = []\n",
    "plot_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self,level,rootObj=None):\n",
    "        self.level = level\n",
    "        self.key = rootObj\n",
    "        self.leftChild = None\n",
    "        self.rightChild = None\n",
    "        self.parent = None\n",
    "        self.sibling = None\n",
    "        self.children = [] \n",
    "        self.hiddenA = None\n",
    "        self.hiddenF = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embedding_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.word_embeddings = nn.Embedding(input_size, embedding_size)    \n",
    "        self.lstm = nn.LSTM(input_size = embedding_size, hidden_size = hidden_size,num_layers = 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input, hidden, c):\n",
    "        embedded = self.word_embeddings(input).view(1, 1, -1)\n",
    "\n",
    "        output = embedded\n",
    "        output,(hidden,c) = self.lstm(output, (hidden, c))\n",
    "        return output,hidden,c\n",
    "\n",
    "    def initCells(self):\n",
    "        \n",
    "        if use_cuda:\n",
    "            return Variable(torch.zeros(1, 1, self.hidden_size).cuda(gpu_no))\n",
    "        else:\n",
    "            return Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderDRNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, decoder_vocab_size):\n",
    "        super(DecoderDRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.word_embeddings = nn.Embedding(decoder_vocab_size, embedding_dim)\n",
    "        self.gruA = nn.GRU(input_size = embedding_dim, hidden_size = hidden_dim,num_layers = 1)\n",
    "        self.gruF = nn.GRU(input_size = embedding_dim, hidden_size = hidden_dim,num_layers = 1)\n",
    "        self.linearA1 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.linearF1 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.projA = nn.Linear(hidden_dim,1)\n",
    "        self.projF = nn.Linear(hidden_dim,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.vA = nn.Linear(1,decoder_vocab_size)\n",
    "        self.vF = nn.Linear(1,decoder_vocab_size)\n",
    "        self.predWeight = nn.Linear(hidden_dim,decoder_vocab_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        init_bias = torch.from_numpy(-np.ones((1,3*hidden_dim)))\n",
    "        self.gruA.bias_hh_l0.data = init_bias.float()\n",
    "        self.gruF.bias_hh_l0.data = init_bias.float()\n",
    "    \n",
    "    def forward(self, hiddenA, hiddenF, parent, sibling):\n",
    "        embeddedA = self.word_embeddings(parent).view(1, 1, -1)\n",
    "        embeddedF = self.word_embeddings(sibling).view(1, 1, -1)\n",
    "        outputA = embeddedA\n",
    "        outputF = embeddedF\n",
    "        outputA, hiddenA = self.gruA(outputA,hiddenA)\n",
    "        outputF, hiddenF = self.gruF(outputF,hiddenF)\n",
    "        hPred = self.tanh(self.linearA1(hiddenA.view(1,-1))+self.linearF1(hiddenF.view(1,-1)))\n",
    "        childPred = self.sigmoid(self.projA(hPred))\n",
    "        siblingPred = self.sigmoid(self.projF(hPred))\n",
    "        \n",
    "            \n",
    "        output = self.predWeight(hPred.view(1,-1))\n",
    "        if(torch.gt(childPred,0.5).data[0][0]):\n",
    "            output += self.vA(childPred)\n",
    "        if(torch.gt(siblingPred,0.5).data[0][0]):\n",
    "            output += self.vF(siblingPred)       \n",
    "        \n",
    "        output = self.log_softmax(output)\n",
    "        return hiddenA,hiddenF,childPred,siblingPred,output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion_label,criterion_topology):\n",
    "    encoder_hidden = encoder.initCells()\n",
    "    encoder_c = encoder.initCells()\n",
    "\n",
    "    input_length = len(input_variable)\n",
    "    target_length = input_length\n",
    "\n",
    "    \n",
    "    if use_cuda:\n",
    "        encoder_hidden = encoder_hidden.cuda(gpu_no)\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden,encoder_c = encoder(input_variable[ei], encoder_hidden,encoder_c)\n",
    "        \n",
    "    decoder_hiddenA = encoder_hidden\n",
    "    decoder_hiddenF = encoder_hidden\n",
    "    \n",
    "    \n",
    "    target_tree_root = target\n",
    "    targetQ = Queue()\n",
    "    targetQ.put(target_tree_root)\n",
    "    \n",
    "    nodesQ = Queue()\n",
    "    root = Tree(level = 0)\n",
    "    nodesQ.put(root)\n",
    "     \n",
    "    prev = root\n",
    "    loss = 0\n",
    "    loss_topo = 0\n",
    "    loss_label = 0\n",
    "    \n",
    "    seq_len = 1\n",
    "    while(not targetQ.empty()):\n",
    "        target_node = targetQ.get()\n",
    "        if(target_node.leftChild != None):\n",
    "            seq_len += 2\n",
    "            targetQ.put(target_node.leftChild)\n",
    "            targetQ.put(target_node.rightChild)\n",
    "        \n",
    "        node = nodesQ.get()\n",
    "        if node.parent == None:\n",
    "            parent = Variable(torch.LongTensor([113]))\n",
    "        else:\n",
    "            parent = node.parent.key\n",
    "            decoder_hiddenA = node.parent.hiddenA\n",
    "        if node.sibling == None:\n",
    "            sibling = Variable(torch.LongTensor([114]))\n",
    "            if node.level != 0:\n",
    "                if use_cuda:\n",
    "                    decoder_hiddenF = Variable(torch.zeros(1, 1, hidden_dim).cuda(gpu_no))\n",
    "                else:\n",
    "                    decoder_hiddenF = Variable(torch.zeros(1, 1, hidden_dim))\n",
    "        else:\n",
    "            sibling = node.sibling.key\n",
    "            decoder_hiddenF = node.sibling.hiddenF\n",
    "            \n",
    "        if use_cuda:\n",
    "            parent = parent.cuda(gpu_no)\n",
    "            sibling = sibling.cuda(gpu_no)\n",
    "\n",
    "        decoder_hiddenA,decoder_hiddenF,childPred,siblingPred,output= decoder(\n",
    "           decoder_hiddenA, decoder_hiddenF, parent, sibling)\n",
    "        \n",
    "        \n",
    "        if(target_node.key in target_op):\n",
    "            target_node.key = target_op[target_node.key]\n",
    "        \n",
    "        if use_cuda:\n",
    "            target_label = Variable(torch.LongTensor([int(target_node.key)])).cuda(gpu_no)\n",
    "        else:\n",
    "            target_label = Variable(torch.LongTensor([int(target_node.key)]))\n",
    "            \n",
    "        loss_label = criterion_label(output,target_label)\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        loss_label.backward(retain_graph = True) \n",
    "        nn.utils.clip_grad_norm(decoder.parameters(), 5)\n",
    "        nn.utils.clip_grad_norm(encoder.parameters(), 5)\n",
    "        \n",
    "        loss += loss_label.data[0]\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        node.key = Variable(torch.LongTensor([int(target_node.key)]))\n",
    "        node.hiddenA = decoder_hiddenA\n",
    "        node.hiddenF = decoder_hiddenF\n",
    "        \n",
    "        \n",
    "        if(target_node.leftChild is not None):\n",
    "            leftChild = Tree(node.level+1)\n",
    "            leftChild.parent = node\n",
    "\n",
    "            if prev.level == leftChild.level:\n",
    "                leftChild.sibling = prev\n",
    "\n",
    "            rightChild = Tree(node.level+1)\n",
    "            rightChild.parent = node\n",
    "            rightChild.sibling = leftChild\n",
    "\n",
    "            prev = rightChild\n",
    "\n",
    "            node.children.append(leftChild)\n",
    "            node.children.append(rightChild)\n",
    "            node.leftChild = leftChild\n",
    "            node.rightChild = rightChild\n",
    "            nodesQ.put(leftChild)\n",
    "            nodesQ.put(rightChild)\n",
    "            \n",
    "            if use_cuda:\n",
    "                target_topo = Variable(torch.FloatTensor([1.0]).view(1,1)).cuda(gpu_no)\n",
    "            else:\n",
    "                target_topo = Variable(torch.FloatTensor([1.0]).view(1,1))\n",
    "            \n",
    "            loss_topo = criterion_topology(childPred,target_topo)\n",
    "            \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            loss_topo.backward(retain_graph = True)\n",
    "            nn.utils.clip_grad_norm(decoder.parameters(), 5)\n",
    "            nn.utils.clip_grad_norm(encoder.parameters(), 5)\n",
    "            \n",
    "            loss += loss_topo.data[0]\n",
    "            \n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "        \n",
    "            \n",
    "                    \n",
    "        if use_cuda:\n",
    "            target_topo = Variable(torch.FloatTensor([0.0]).view(1,1)).cuda(gpu_no)\n",
    "        else:\n",
    "            target_topo = Variable(torch.FloatTensor([0.0]).view(1,1))\n",
    "        \n",
    "        if(target_node.leftChild is None and torch.gt(childPred,0.5).data[0][0]):\n",
    "            loss_topo = criterion_topology(childPred,target_topo)\n",
    "            \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            \n",
    "            loss_topo.backward(retain_graph = True)\n",
    "            nn.utils.clip_grad_norm(decoder.parameters(), 5)\n",
    "            nn.utils.clip_grad_norm(encoder.parameters(), 5)\n",
    "            \n",
    "            loss += loss_topo.data[0]\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step() \n",
    "     \n",
    "\n",
    "    return loss/ target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, training_pairs, print_every=1000, plot_every=100, learning_rate=0.05):\n",
    "    start = time.time()\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion_label = nn.NLLLoss()\n",
    "    criterion_topo = nn.BCELoss()\n",
    "\n",
    "    flip = True\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = Variable(torch.LongTensor(training_pair[0]).view(-1, 1))\n",
    "        target = training_pair[1]\n",
    "        \n",
    "        if use_cuda:\n",
    "            input_variable = input_variable.cuda(gpu_no)\n",
    "\n",
    "        loss = train(input_variable, target, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion_label,criterion_topo)\n",
    "        print_loss_total += loss\n",
    "        plot_losses.append(loss)\n",
    "        \n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            plot_loss_avg.append(print_loss_avg)\n",
    "            print_loss_total = 0\n",
    "            if flip:\n",
    "                torch.save(encoder.state_dict(), './pickles/encoder_drnn_relabel1.pth')\n",
    "                torch.save(decoder.state_dict(), './pickles/decoder_drnn_relabel1.pth')\n",
    "                flip = False\n",
    "            else:\n",
    "                torch.save(encoder.state_dict(), './pickles/encoder_drnn_relabel2.pth')\n",
    "                torch.save(decoder.state_dict(), './pickles/decoder_drnn_relabel2.pth')\n",
    "                flip = True\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "[[109, 89, 60, 109, 98, 24, 109, 97, 31, 99, 110, 110, 110], <TreeConstructor.Target object at 0x7f71f3a867b8>]\n",
      "/\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 256\n",
    "embedding_size = 256\n",
    "gpu_no = 1\n",
    "\n",
    "#0-108,(,)\n",
    "encoder_vocab_size = 111\n",
    "\n",
    "# 0-108,+,-,*,/, no parent, no child\n",
    "decoder_vocab_size = 115\n",
    "\n",
    "use_cuda = True\n",
    "n_iters = 5000000\n",
    "train_filename = \"/data2/t2t/synth_data/relabel/train.orig\"\n",
    "target_filename = \"/data2/t2t/synth_data/relabel/train.interior_relabel\"\n",
    "\n",
    "\n",
    "target_op = {'+':'109', '-':'110','*':'111','/':'112'}\n",
    "\n",
    "training_pairs = generate_training_data(n_iters,train_filename,target_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 30s (- 75076m 50s) (100 0%) 2.6915\n",
      "3m 25s (- 85796m 10s) (200 0%) 2.6536\n",
      "4m 46s (- 79595m 17s) (300 0%) 2.6960\n",
      "6m 25s (- 80284m 38s) (400 0%) 2.5125\n",
      "7m 56s (- 79372m 4s) (500 0%) 2.5464\n",
      "9m 31s (- 79429m 19s) (600 0%) 2.4514\n",
      "11m 2s (- 78819m 1s) (700 0%) 2.4287\n",
      "12m 36s (- 78827m 55s) (800 0%) 2.3329\n",
      "14m 16s (- 79267m 5s) (900 0%) 2.2596\n",
      "15m 57s (- 79817m 3s) (1000 0%) 2.2515\n",
      "17m 40s (- 80301m 35s) (1100 0%) 2.2678\n",
      "19m 22s (- 80744m 0s) (1200 0%) 2.2834\n",
      "21m 5s (- 81077m 2s) (1300 0%) 2.2698\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ee32170eb5d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdecoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-058ba7be229f>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, training_pairs, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         loss = train(input_variable, target, encoder,\n\u001b[0;32m---> 19\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion_label,criterion_topo)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mplot_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-354299908bc6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion_label, criterion_topology)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mloss_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder1 = EncoderLSTM(encoder_vocab_size, hidden_dim,embedding_size)\n",
    "decoder1 = DecoderDRNN(embedding_size,hidden_dim,decoder_vocab_size)\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda(gpu_no)\n",
    "    decoder1 = decoder1.cuda(gpu_no)\n",
    "\n",
    "trainIters(encoder1,decoder1, n_iters, training_pairs,print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_loss_avg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-96065857e589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sgd-out'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_loss_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_loss_avg' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('relabel-out', 'wb') as fp:\n",
    "    pickle.dump(plot_loss_avg, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
