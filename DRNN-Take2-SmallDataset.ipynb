{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from queue import *\n",
    "\n",
    "from DataLoader import *\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(n_iters,filename):\n",
    "    data_loader = T2TDataLoader(filename)\n",
    "    training_data = data_loader.get_data()\n",
    "    print(len(training_data))\n",
    "    training_pairs = [(random.choice(training_data))\n",
    "                      for i in range(n_iters)]\n",
    "    print(training_pairs[0])\n",
    "    print(training_pairs[0][1].key)\n",
    "    return training_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_avg = []\n",
    "plot_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self,level,rootObj=None):\n",
    "        self.level = level\n",
    "        self.key = rootObj\n",
    "        self.leftChild = None\n",
    "        self.rightChild = None\n",
    "        self.parent = None\n",
    "        self.sibling = None\n",
    "        self.children = [] \n",
    "        self.hiddenA = None\n",
    "        self.hiddenF = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embedding_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.word_embeddings = nn.Embedding(input_size, embedding_size)    \n",
    "        self.lstm = nn.LSTM(input_size = embedding_size, hidden_size = hidden_size,num_layers = 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input, hidden, c):\n",
    "        embedded = self.word_embeddings(input).view(1, 1, -1)\n",
    "\n",
    "        output = embedded\n",
    "        output,(hidden,c) = self.lstm(output, (hidden, c))\n",
    "        return output,hidden,c\n",
    "\n",
    "    def initCells(self):\n",
    "        \n",
    "        if use_cuda:\n",
    "            return Variable(torch.zeros(1, 1, self.hidden_size).cuda(gpu_no))\n",
    "        else:\n",
    "            return Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderDRNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, decoder_vocab_size):\n",
    "        super(DecoderDRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.word_embeddings = nn.Embedding(decoder_vocab_size, embedding_dim)\n",
    "        self.gruA = nn.GRU(input_size = embedding_dim, hidden_size = hidden_dim,num_layers = 1)\n",
    "        self.gruF = nn.GRU(input_size = embedding_dim, hidden_size = hidden_dim,num_layers = 1)\n",
    "        self.linearA1 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.linearF1 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.projA = nn.Linear(hidden_dim,1)\n",
    "        self.projF = nn.Linear(hidden_dim,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        #Note the -2\n",
    "        self.vA = nn.Linear(1,decoder_vocab_size-2)\n",
    "        self.vF = nn.Linear(1,decoder_vocab_size-2)\n",
    "        self.predWeight = nn.Linear(hidden_dim,decoder_vocab_size-2)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        init_bias = torch.from_numpy(-np.ones((1,3*hidden_dim)))\n",
    "        self.gruA.bias_hh_l0.data = init_bias.float()\n",
    "        self.gruF.bias_hh_l0.data = init_bias.float()\n",
    "    \n",
    "    def forward(self, hiddenA, hiddenF, parent, sibling):\n",
    "        embeddedA = self.word_embeddings(parent).view(1, 1, -1)\n",
    "        embeddedF = self.word_embeddings(sibling).view(1, 1, -1)\n",
    "        outputA = embeddedA\n",
    "        outputF = embeddedF\n",
    "        outputA, hiddenA = self.gruA(outputA,hiddenA)\n",
    "        outputF, hiddenF = self.gruF(outputF,hiddenF)\n",
    "        hPred = self.tanh(self.linearA1(hiddenA.view(1,-1))+self.linearF1(hiddenF.view(1,-1)))\n",
    "        childPred = self.sigmoid(self.projA(hPred))\n",
    "        siblingPred = self.sigmoid(self.projF(hPred))\n",
    "        \n",
    "            \n",
    "        output = self.predWeight(hPred.view(1,-1))\n",
    "        if(torch.gt(childPred,0.5).data[0][0]):\n",
    "            output += self.vA(childPred)\n",
    "        if(torch.gt(siblingPred,0.5).data[0][0]):\n",
    "            output += self.vF(siblingPred)       \n",
    "        \n",
    "        output = self.log_softmax(output)\n",
    "        return hiddenA,hiddenF,childPred,siblingPred,output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion_label,criterion_topology):\n",
    "    encoder_hidden = encoder.initCells()\n",
    "    encoder_c = encoder.initCells()\n",
    "\n",
    "    input_length = len(input_variable)\n",
    "    target_length = input_length\n",
    "\n",
    "    \n",
    "    if use_cuda:\n",
    "        encoder_hidden = encoder_hidden.cuda()\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden,encoder_c = encoder(input_variable[ei], encoder_hidden,encoder_c)\n",
    "        \n",
    "    decoder_hiddenA = encoder_hidden\n",
    "    decoder_hiddenF = encoder_hidden\n",
    "    \n",
    "    \n",
    "    target_tree_root = target\n",
    "    targetQ = Queue()\n",
    "    targetQ.put(target_tree_root)\n",
    "    \n",
    "    nodesQ = Queue()\n",
    "    root = Tree(level = 0)\n",
    "    nodesQ.put(root)\n",
    "     \n",
    "    prev = root\n",
    "    loss = 0\n",
    "    loss_topo = 0\n",
    "    loss_label = 0\n",
    "    \n",
    "    seq_len = 1\n",
    "    while(not targetQ.empty()):\n",
    "        target_node = targetQ.get()\n",
    "        if(target_node.leftChild != None):\n",
    "            seq_len += 2\n",
    "            targetQ.put(target_node.leftChild)\n",
    "            targetQ.put(target_node.rightChild)\n",
    "        \n",
    "        node = nodesQ.get()\n",
    "        if node.parent == None:\n",
    "            parent = Variable(torch.LongTensor([106]))\n",
    "            #parent = 106\n",
    "        else:\n",
    "            parent = node.parent.key\n",
    "            decoder_hiddenA = node.parent.hiddenA\n",
    "        if node.sibling == None:\n",
    "            #sibling = 107\n",
    "            sibling = Variable(torch.LongTensor([107]))\n",
    "            if node.level != 0:\n",
    "                if use_cuda:\n",
    "                    decoder_hiddenF = Variable(torch.zeros(1, 1, hidden_dim).cuda(gpu_no))\n",
    "                else:\n",
    "                    decoder_hiddenF = Variable(torch.zeros(1, 1, hidden_dim))\n",
    "        else:\n",
    "            sibling = node.sibling.key\n",
    "            decoder_hiddenF = node.sibling.hiddenF\n",
    "            \n",
    "        if use_cuda:\n",
    "            parent = parent.cuda(gpu_no)\n",
    "            sibling = sibling.cuda(gpu_no)\n",
    "\n",
    "        decoder_hiddenA,decoder_hiddenF,childPred,siblingPred,output= decoder(\n",
    "           decoder_hiddenA, decoder_hiddenF, parent, sibling)\n",
    "        \n",
    "        \n",
    "        if(target_node.key in target_op):\n",
    "            target_node.key = target_op[target_node.key]\n",
    "        \n",
    "        if use_cuda:\n",
    "            target_label = Variable(torch.LongTensor([int(target_node.key)])).cuda(gpu_no)\n",
    "        else:\n",
    "            target_label = Variable(torch.LongTensor([int(target_node.key)]))\n",
    "            \n",
    "        loss_label = criterion_label(output,target_label)\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        loss_label.backward(retain_graph = True) \n",
    "        nn.utils.clip_grad_norm(decoder.parameters(), 5)\n",
    "        nn.utils.clip_grad_norm(encoder.parameters(), 5)\n",
    "        \n",
    "        loss += loss_label.data[0]\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        node.key = Variable(torch.LongTensor([int(target_node.key)]))\n",
    "        node.hiddenA = decoder_hiddenA\n",
    "        node.hiddenF = decoder_hiddenF\n",
    "        \n",
    "        \n",
    "        if(target_node.leftChild is not None):\n",
    "            leftChild = Tree(node.level+1)\n",
    "            leftChild.parent = node\n",
    "\n",
    "            if prev.level == leftChild.level:\n",
    "                leftChild.sibling = prev\n",
    "\n",
    "            rightChild = Tree(node.level+1)\n",
    "            rightChild.parent = node\n",
    "            rightChild.sibling = leftChild\n",
    "\n",
    "            prev = rightChild\n",
    "\n",
    "            node.children.append(leftChild)\n",
    "            node.children.append(rightChild)\n",
    "            node.leftChild = leftChild\n",
    "            node.rightChild = rightChild\n",
    "            nodesQ.put(leftChild)\n",
    "            nodesQ.put(rightChild)\n",
    "            \n",
    "            if use_cuda:\n",
    "                target_topo = Variable(torch.FloatTensor([1.0]).view(1,1)).cuda(gpu_no)\n",
    "            else:\n",
    "                target_topo = Variable(torch.FloatTensor([1.0]).view(1,1))\n",
    "            \n",
    "            loss_topo = criterion_topology(childPred,target_topo)\n",
    "            \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            loss_topo.backward(retain_graph = True)\n",
    "            nn.utils.clip_grad_norm(decoder.parameters(), 5)\n",
    "            nn.utils.clip_grad_norm(encoder.parameters(), 5)\n",
    "            \n",
    "            loss += loss_topo.data[0]\n",
    "            \n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "        \n",
    "            \n",
    "                    \n",
    "        if use_cuda:\n",
    "            target_topo = Variable(torch.FloatTensor([0.0]).view(1,1)).cuda(gpu_no)\n",
    "        else:\n",
    "            target_topo = Variable(torch.FloatTensor([0.0]).view(1,1))\n",
    "        \n",
    "        if(target_node.leftChild is None and torch.gt(childPred,0.5).data[0][0]):\n",
    "            loss_topo = criterion_topology(childPred,target_topo)\n",
    "            \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            \n",
    "            loss_topo.backward(retain_graph = True)\n",
    "            nn.utils.clip_grad_norm(decoder.parameters(), 5)\n",
    "            nn.utils.clip_grad_norm(encoder.parameters(), 5)\n",
    "            \n",
    "            loss += loss_topo.data[0]\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step() \n",
    "     \n",
    "\n",
    "    return loss/ target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, training_pairs, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion_label = nn.NLLLoss()\n",
    "    criterion_topo = nn.BCELoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = Variable(torch.LongTensor(training_pair[0]).view(-1, 1))\n",
    "        target = training_pair[1]\n",
    "        \n",
    "        if use_cuda:\n",
    "            input_variable = input_variable.cuda(gpu_no)\n",
    "\n",
    "        loss = train(input_variable, target, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion_label,criterion_topo)\n",
    "        print_loss_total += loss\n",
    "        plot_losses.append(loss)\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            plot_loss_avg.append(print_loss_avg)\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "[[104, 64, 100, 36, 105], <TreeParser.BinaryTree object at 0x7fa89e4852b0>, 2]\n",
      "+\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 256\n",
    "embedding_size = 256\n",
    "gpu_no = 0\n",
    "# 0-99,+,-,*,/,(,)\n",
    "encoder_vocab_size = 106\n",
    "decoder_vocab_size = 108\n",
    "use_cuda = True\n",
    "n_iters = 50000\n",
    "filename = \"/data2/t2t/train.orig\"\n",
    "target_op = {'+':'100', '-':'101','*':'102','/':'103'}\n",
    "\n",
    "training_pairs = generate_training_data(n_iters,filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 6s (- 51m 10s) (100 0%) 2.4465\n",
      "0m 12s (- 51m 30s) (200 0%) 2.1983\n",
      "0m 18s (- 51m 29s) (300 0%) 2.1759\n",
      "0m 24s (- 51m 28s) (400 0%) 2.1643\n",
      "0m 30s (- 50m 59s) (500 1%) 2.1744\n",
      "0m 37s (- 51m 13s) (600 1%) 2.1747\n",
      "0m 44s (- 52m 16s) (700 1%) 2.1286\n",
      "0m 51s (- 52m 46s) (800 1%) 2.1415\n",
      "0m 57s (- 52m 14s) (900 1%) 2.1169\n",
      "1m 3s (- 51m 52s) (1000 2%) 2.1094\n",
      "1m 9s (- 51m 37s) (1100 2%) 2.0832\n",
      "1m 16s (- 51m 35s) (1200 2%) 2.0480\n",
      "1m 22s (- 51m 23s) (1300 2%) 1.9378\n",
      "1m 28s (- 51m 11s) (1400 2%) 1.8968\n",
      "1m 34s (- 51m 0s) (1500 3%) 1.8932\n",
      "1m 40s (- 50m 38s) (1600 3%) 1.8366\n",
      "1m 46s (- 50m 24s) (1700 3%) 1.8321\n",
      "1m 52s (- 50m 14s) (1800 3%) 1.7732\n",
      "1m 58s (- 50m 9s) (1900 3%) 1.7808\n",
      "2m 4s (- 49m 57s) (2000 4%) 1.7946\n",
      "2m 11s (- 49m 50s) (2100 4%) 1.8006\n",
      "2m 17s (- 49m 46s) (2200 4%) 1.7787\n",
      "2m 23s (- 49m 33s) (2300 4%) 1.7173\n",
      "2m 29s (- 49m 26s) (2400 4%) 1.7786\n",
      "2m 35s (- 49m 15s) (2500 5%) 1.7434\n",
      "2m 41s (- 49m 2s) (2600 5%) 1.7530\n",
      "2m 47s (- 48m 53s) (2700 5%) 1.7434\n",
      "2m 53s (- 48m 38s) (2800 5%) 1.7368\n",
      "2m 58s (- 48m 22s) (2900 5%) 1.6917\n",
      "3m 4s (- 48m 12s) (3000 6%) 1.7218\n",
      "3m 10s (- 47m 57s) (3100 6%) 1.7218\n",
      "3m 15s (- 47m 44s) (3200 6%) 1.7472\n",
      "3m 21s (- 47m 33s) (3300 6%) 1.7353\n",
      "3m 27s (- 47m 19s) (3400 6%) 1.6957\n",
      "3m 32s (- 47m 7s) (3500 7%) 1.6514\n",
      "3m 38s (- 46m 53s) (3600 7%) 1.7421\n",
      "3m 42s (- 46m 27s) (3700 7%) 1.7299\n",
      "3m 48s (- 46m 13s) (3800 7%) 1.7023\n",
      "3m 52s (- 45m 54s) (3900 7%) 1.6832\n",
      "3m 57s (- 45m 33s) (4000 8%) 1.6638\n",
      "4m 2s (- 45m 16s) (4100 8%) 1.6898\n",
      "4m 7s (- 44m 59s) (4200 8%) 1.6638\n",
      "4m 12s (- 44m 41s) (4300 8%) 1.6685\n",
      "4m 17s (- 44m 24s) (4400 8%) 1.6635\n",
      "4m 21s (- 44m 9s) (4500 9%) 1.6874\n",
      "4m 26s (- 43m 52s) (4600 9%) 1.6353\n",
      "4m 31s (- 43m 36s) (4700 9%) 1.7053\n",
      "4m 36s (- 43m 22s) (4800 9%) 1.6450\n",
      "4m 41s (- 43m 7s) (4900 9%) 1.5956\n",
      "4m 45s (- 42m 52s) (5000 10%) 1.6361\n",
      "4m 50s (- 42m 39s) (5100 10%) 1.6449\n",
      "4m 55s (- 42m 25s) (5200 10%) 1.6760\n",
      "5m 0s (- 42m 11s) (5300 10%) 1.6310\n",
      "5m 5s (- 41m 59s) (5400 10%) 1.5888\n",
      "5m 9s (- 41m 46s) (5500 11%) 1.6272\n",
      "5m 14s (- 41m 33s) (5600 11%) 1.5630\n",
      "5m 19s (- 41m 22s) (5700 11%) 1.5035\n",
      "5m 24s (- 41m 11s) (5800 11%) 1.5616\n",
      "5m 29s (- 41m 4s) (5900 11%) 1.5657\n",
      "5m 35s (- 40m 58s) (6000 12%) 1.5453\n",
      "5m 40s (- 40m 50s) (6100 12%) 1.5735\n",
      "5m 46s (- 40m 45s) (6200 12%) 1.5302\n",
      "5m 51s (- 40m 37s) (6300 12%) 1.4124\n",
      "5m 56s (- 40m 30s) (6400 12%) 1.4857\n",
      "6m 2s (- 40m 24s) (6500 13%) 1.4988\n",
      "6m 7s (- 40m 16s) (6600 13%) 1.4899\n",
      "6m 12s (- 40m 8s) (6700 13%) 1.4785\n",
      "6m 18s (- 40m 3s) (6800 13%) 1.4265\n",
      "6m 23s (- 39m 55s) (6900 13%) 1.4360\n",
      "6m 28s (- 39m 47s) (7000 14%) 1.3767\n",
      "6m 34s (- 39m 42s) (7100 14%) 1.3809\n",
      "6m 39s (- 39m 35s) (7200 14%) 1.2888\n",
      "6m 44s (- 39m 28s) (7300 14%) 1.2312\n",
      "6m 50s (- 39m 23s) (7400 14%) 1.2574\n",
      "6m 55s (- 39m 16s) (7500 15%) 1.2934\n",
      "7m 1s (- 39m 9s) (7600 15%) 1.2623\n",
      "7m 6s (- 39m 4s) (7700 15%) 1.1653\n",
      "7m 12s (- 38m 57s) (7800 15%) 1.1787\n",
      "7m 17s (- 38m 50s) (7900 15%) 1.1049\n",
      "7m 22s (- 38m 45s) (8000 16%) 1.0750\n",
      "7m 28s (- 38m 39s) (8100 16%) 1.1532\n",
      "7m 33s (- 38m 32s) (8200 16%) 1.0332\n",
      "7m 39s (- 38m 27s) (8300 16%) 1.1244\n",
      "7m 44s (- 38m 21s) (8400 16%) 1.0528\n",
      "7m 49s (- 38m 12s) (8500 17%) 0.9569\n",
      "7m 54s (- 38m 4s) (8600 17%) 1.0364\n",
      "7m 59s (- 37m 55s) (8700 17%) 1.0058\n",
      "8m 4s (- 37m 46s) (8800 17%) 0.9634\n",
      "8m 9s (- 37m 38s) (8900 17%) 0.9605\n",
      "8m 13s (- 37m 29s) (9000 18%) 0.8824\n",
      "8m 18s (- 37m 20s) (9100 18%) 0.8245\n",
      "8m 23s (- 37m 12s) (9200 18%) 0.9074\n",
      "8m 28s (- 37m 3s) (9300 18%) 0.8624\n",
      "8m 33s (- 36m 56s) (9400 18%) 0.8935\n",
      "8m 37s (- 36m 47s) (9500 19%) 0.8535\n",
      "8m 42s (- 36m 38s) (9600 19%) 0.7570\n",
      "8m 47s (- 36m 30s) (9700 19%) 0.8609\n",
      "8m 52s (- 36m 23s) (9800 19%) 0.7549\n",
      "8m 56s (- 36m 14s) (9900 19%) 0.8178\n",
      "9m 1s (- 36m 7s) (10000 20%) 0.8524\n",
      "9m 6s (- 35m 59s) (10100 20%) 0.7072\n",
      "9m 11s (- 35m 51s) (10200 20%) 0.7344\n",
      "9m 16s (- 35m 44s) (10300 20%) 0.7079\n",
      "9m 21s (- 35m 36s) (10400 20%) 0.6905\n",
      "9m 25s (- 35m 28s) (10500 21%) 0.6648\n",
      "9m 30s (- 35m 21s) (10600 21%) 0.6602\n",
      "9m 35s (- 35m 13s) (10700 21%) 0.6388\n",
      "9m 40s (- 35m 5s) (10800 21%) 0.5539\n",
      "9m 45s (- 34m 59s) (10900 21%) 0.6174\n",
      "9m 49s (- 34m 51s) (11000 22%) 0.6225\n",
      "9m 54s (- 34m 43s) (11100 22%) 0.5749\n",
      "9m 59s (- 34m 37s) (11200 22%) 0.6165\n",
      "10m 4s (- 34m 29s) (11300 22%) 0.5514\n",
      "10m 9s (- 34m 22s) (11400 22%) 0.5556\n",
      "10m 13s (- 34m 15s) (11500 23%) 0.5159\n",
      "10m 18s (- 34m 8s) (11600 23%) 0.6111\n",
      "10m 23s (- 34m 0s) (11700 23%) 0.5158\n",
      "10m 28s (- 33m 54s) (11800 23%) 0.4947\n",
      "10m 33s (- 33m 46s) (11900 23%) 0.5462\n",
      "10m 37s (- 33m 39s) (12000 24%) 0.4831\n",
      "10m 42s (- 33m 33s) (12100 24%) 0.5364\n",
      "10m 47s (- 33m 26s) (12200 24%) 0.5204\n",
      "10m 52s (- 33m 19s) (12300 24%) 0.4278\n",
      "10m 57s (- 33m 12s) (12400 24%) 0.4188\n",
      "11m 1s (- 33m 5s) (12500 25%) 0.4821\n",
      "11m 6s (- 32m 58s) (12600 25%) 0.4750\n",
      "11m 11s (- 32m 52s) (12700 25%) 0.4516\n",
      "11m 16s (- 32m 45s) (12800 25%) 0.4808\n",
      "11m 21s (- 32m 38s) (12900 25%) 0.4340\n",
      "11m 25s (- 32m 32s) (13000 26%) 0.4224\n",
      "11m 30s (- 32m 25s) (13100 26%) 0.4050\n",
      "11m 35s (- 32m 18s) (13200 26%) 0.3486\n",
      "11m 40s (- 32m 12s) (13300 26%) 0.3845\n",
      "11m 44s (- 32m 5s) (13400 26%) 0.3701\n",
      "11m 49s (- 31m 58s) (13500 27%) 0.3632\n",
      "11m 54s (- 31m 52s) (13600 27%) 0.4000\n",
      "11m 59s (- 31m 46s) (13700 27%) 0.3871\n",
      "12m 4s (- 31m 40s) (13800 27%) 0.2868\n",
      "12m 9s (- 31m 34s) (13900 27%) 0.3764\n",
      "12m 14s (- 31m 28s) (14000 28%) 0.2789\n",
      "12m 19s (- 31m 22s) (14100 28%) 0.2636\n",
      "12m 24s (- 31m 16s) (14200 28%) 0.2894\n",
      "12m 29s (- 31m 10s) (14300 28%) 0.2790\n",
      "12m 34s (- 31m 6s) (14400 28%) 0.2440\n",
      "12m 40s (- 31m 0s) (14500 28%) 0.2723\n",
      "12m 45s (- 30m 55s) (14600 29%) 0.3246\n",
      "12m 50s (- 30m 51s) (14700 29%) 0.3378\n",
      "12m 55s (- 30m 44s) (14800 29%) 0.2198\n",
      "13m 0s (- 30m 38s) (14900 29%) 0.2505\n",
      "13m 5s (- 30m 32s) (15000 30%) 0.2769\n",
      "13m 10s (- 30m 26s) (15100 30%) 0.2462\n",
      "13m 14s (- 30m 20s) (15200 30%) 0.2668\n",
      "13m 20s (- 30m 14s) (15300 30%) 0.1810\n",
      "13m 24s (- 30m 8s) (15400 30%) 0.2195\n",
      "13m 29s (- 30m 1s) (15500 31%) 0.2198\n",
      "13m 34s (- 29m 56s) (15600 31%) 0.2102\n",
      "13m 39s (- 29m 51s) (15700 31%) 0.1902\n",
      "13m 44s (- 29m 45s) (15800 31%) 0.1768\n",
      "13m 49s (- 29m 40s) (15900 31%) 0.1887\n",
      "13m 54s (- 29m 33s) (16000 32%) 0.2282\n",
      "13m 59s (- 29m 27s) (16100 32%) 0.2027\n",
      "14m 4s (- 29m 22s) (16200 32%) 0.2381\n",
      "14m 9s (- 29m 17s) (16300 32%) 0.1932\n",
      "14m 14s (- 29m 11s) (16400 32%) 0.1863\n",
      "14m 20s (- 29m 6s) (16500 33%) 0.1762\n",
      "14m 25s (- 29m 1s) (16600 33%) 0.1531\n",
      "14m 30s (- 28m 56s) (16700 33%) 0.1548\n",
      "14m 36s (- 28m 51s) (16800 33%) 0.1422\n",
      "14m 41s (- 28m 46s) (16900 33%) 0.1696\n",
      "14m 46s (- 28m 41s) (17000 34%) 0.1263\n",
      "14m 51s (- 28m 35s) (17100 34%) 0.1288\n",
      "14m 56s (- 28m 28s) (17200 34%) 0.1579\n",
      "15m 1s (- 28m 23s) (17300 34%) 0.1490\n",
      "15m 5s (- 28m 16s) (17400 34%) 0.1372\n",
      "15m 10s (- 28m 11s) (17500 35%) 0.1277\n",
      "15m 16s (- 28m 7s) (17600 35%) 0.1287\n",
      "15m 21s (- 28m 1s) (17700 35%) 0.1445\n",
      "15m 26s (- 27m 56s) (17800 35%) 0.1434\n",
      "15m 32s (- 27m 52s) (17900 35%) 0.1251\n",
      "15m 37s (- 27m 47s) (18000 36%) 0.1083\n",
      "15m 42s (- 27m 41s) (18100 36%) 0.1316\n",
      "15m 48s (- 27m 37s) (18200 36%) 0.1288\n",
      "15m 53s (- 27m 32s) (18300 36%) 0.0974\n",
      "15m 58s (- 27m 26s) (18400 36%) 0.0893\n",
      "16m 4s (- 27m 22s) (18500 37%) 0.1179\n",
      "16m 9s (- 27m 17s) (18600 37%) 0.0952\n",
      "16m 15s (- 27m 12s) (18700 37%) 0.0843\n",
      "16m 20s (- 27m 7s) (18800 37%) 0.1036\n",
      "16m 25s (- 27m 1s) (18900 37%) 0.0851\n",
      "16m 30s (- 26m 55s) (19000 38%) 0.0932\n",
      "16m 35s (- 26m 50s) (19100 38%) 0.0824\n",
      "16m 40s (- 26m 45s) (19200 38%) 0.0883\n",
      "16m 45s (- 26m 40s) (19300 38%) 0.0718\n",
      "16m 51s (- 26m 35s) (19400 38%) 0.0799\n",
      "16m 56s (- 26m 30s) (19500 39%) 0.0658\n",
      "17m 2s (- 26m 25s) (19600 39%) 0.0765\n",
      "17m 7s (- 26m 20s) (19700 39%) 0.0692\n",
      "17m 12s (- 26m 15s) (19800 39%) 0.0875\n",
      "17m 18s (- 26m 10s) (19900 39%) 0.0744\n",
      "17m 24s (- 26m 6s) (20000 40%) 0.0525\n",
      "17m 29s (- 26m 0s) (20100 40%) 0.0675\n",
      "17m 33s (- 25m 54s) (20200 40%) 0.0678\n",
      "17m 38s (- 25m 49s) (20300 40%) 0.0640\n",
      "17m 43s (- 25m 43s) (20400 40%) 0.0457\n",
      "17m 48s (- 25m 37s) (20500 41%) 0.0636\n",
      "17m 53s (- 25m 31s) (20600 41%) 0.0548\n",
      "17m 58s (- 25m 26s) (20700 41%) 0.0552\n",
      "18m 2s (- 25m 20s) (20800 41%) 0.0497\n",
      "18m 8s (- 25m 14s) (20900 41%) 0.0638\n",
      "18m 12s (- 25m 9s) (21000 42%) 0.0536\n",
      "18m 17s (- 25m 3s) (21100 42%) 0.0636\n",
      "18m 22s (- 24m 57s) (21200 42%) 0.0510\n",
      "18m 27s (- 24m 52s) (21300 42%) 0.0579\n",
      "18m 32s (- 24m 46s) (21400 42%) 0.0594\n",
      "18m 37s (- 24m 40s) (21500 43%) 0.0430\n",
      "18m 41s (- 24m 34s) (21600 43%) 0.0480\n",
      "18m 46s (- 24m 29s) (21700 43%) 0.0531\n",
      "18m 51s (- 24m 23s) (21800 43%) 0.0452\n",
      "18m 56s (- 24m 18s) (21900 43%) 0.0411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19m 1s (- 24m 12s) (22000 44%) 0.0433\n",
      "19m 6s (- 24m 6s) (22100 44%) 0.0277\n",
      "19m 10s (- 24m 1s) (22200 44%) 0.0543\n",
      "19m 15s (- 23m 55s) (22300 44%) 0.0489\n",
      "19m 20s (- 23m 50s) (22400 44%) 0.0501\n",
      "19m 25s (- 23m 44s) (22500 45%) 0.0387\n",
      "19m 30s (- 23m 38s) (22600 45%) 0.0317\n",
      "19m 35s (- 23m 33s) (22700 45%) 0.0293\n",
      "19m 39s (- 23m 27s) (22800 45%) 0.0325\n",
      "19m 44s (- 23m 22s) (22900 45%) 0.0292\n",
      "19m 49s (- 23m 16s) (23000 46%) 0.0375\n",
      "19m 54s (- 23m 11s) (23100 46%) 0.0385\n",
      "19m 59s (- 23m 5s) (23200 46%) 0.0393\n",
      "20m 4s (- 23m 0s) (23300 46%) 0.0312\n",
      "20m 10s (- 22m 55s) (23400 46%) 0.0355\n",
      "20m 15s (- 22m 50s) (23500 47%) 0.0308\n",
      "20m 20s (- 22m 45s) (23600 47%) 0.0219\n",
      "20m 25s (- 22m 40s) (23700 47%) 0.0317\n",
      "20m 31s (- 22m 35s) (23800 47%) 0.0312\n",
      "20m 36s (- 22m 30s) (23900 47%) 0.0342\n",
      "20m 41s (- 22m 25s) (24000 48%) 0.0273\n",
      "20m 47s (- 22m 20s) (24100 48%) 0.0368\n",
      "20m 52s (- 22m 15s) (24200 48%) 0.0343\n",
      "20m 57s (- 22m 10s) (24300 48%) 0.0272\n",
      "21m 3s (- 22m 5s) (24400 48%) 0.0250\n",
      "21m 8s (- 22m 0s) (24500 49%) 0.0334\n",
      "21m 13s (- 21m 54s) (24600 49%) 0.0255\n",
      "21m 18s (- 21m 50s) (24700 49%) 0.0156\n",
      "21m 24s (- 21m 44s) (24800 49%) 0.0200\n",
      "21m 29s (- 21m 39s) (24900 49%) 0.0220\n",
      "21m 34s (- 21m 34s) (25000 50%) 0.0246\n",
      "21m 39s (- 21m 29s) (25100 50%) 0.0222\n",
      "21m 45s (- 21m 24s) (25200 50%) 0.0255\n",
      "21m 50s (- 21m 19s) (25300 50%) 0.0312\n",
      "21m 55s (- 21m 14s) (25400 50%) 0.0300\n",
      "22m 0s (- 21m 9s) (25500 51%) 0.0196\n",
      "22m 6s (- 21m 3s) (25600 51%) 0.0245\n",
      "22m 11s (- 20m 58s) (25700 51%) 0.0239\n",
      "22m 16s (- 20m 53s) (25800 51%) 0.0166\n",
      "22m 21s (- 20m 48s) (25900 51%) 0.0176\n",
      "22m 26s (- 20m 43s) (26000 52%) 0.0177\n",
      "22m 32s (- 20m 38s) (26100 52%) 0.0238\n",
      "22m 37s (- 20m 33s) (26200 52%) 0.0165\n",
      "22m 43s (- 20m 28s) (26300 52%) 0.0193\n",
      "22m 48s (- 20m 23s) (26400 52%) 0.0194\n",
      "22m 53s (- 20m 18s) (26500 53%) 0.0152\n",
      "22m 59s (- 20m 13s) (26600 53%) 0.0155\n",
      "23m 4s (- 20m 8s) (26700 53%) 0.0221\n",
      "23m 9s (- 20m 2s) (26800 53%) 0.0165\n",
      "23m 14s (- 19m 57s) (26900 53%) 0.0166\n",
      "23m 20s (- 19m 52s) (27000 54%) 0.0267\n",
      "23m 25s (- 19m 47s) (27100 54%) 0.0176\n",
      "23m 30s (- 19m 42s) (27200 54%) 0.0138\n",
      "23m 35s (- 19m 37s) (27300 54%) 0.0154\n",
      "23m 41s (- 19m 32s) (27400 54%) 0.0154\n",
      "23m 46s (- 19m 27s) (27500 55%) 0.0125\n",
      "23m 51s (- 19m 22s) (27600 55%) 0.0191\n",
      "23m 57s (- 19m 17s) (27700 55%) 0.0127\n",
      "24m 2s (- 19m 12s) (27800 55%) 0.0175\n",
      "24m 8s (- 19m 7s) (27900 55%) 0.0134\n",
      "24m 14s (- 19m 2s) (28000 56%) 0.0168\n",
      "24m 19s (- 18m 57s) (28100 56%) 0.0131\n",
      "24m 25s (- 18m 53s) (28200 56%) 0.0186\n",
      "24m 31s (- 18m 48s) (28300 56%) 0.0142\n",
      "24m 37s (- 18m 43s) (28400 56%) 0.0189\n",
      "24m 42s (- 18m 38s) (28500 56%) 0.0131\n",
      "24m 48s (- 18m 33s) (28600 57%) 0.0149\n",
      "24m 53s (- 18m 28s) (28700 57%) 0.0111\n",
      "24m 59s (- 18m 23s) (28800 57%) 0.0176\n",
      "25m 4s (- 18m 18s) (28900 57%) 0.0102\n",
      "25m 9s (- 18m 13s) (29000 57%) 0.0108\n",
      "25m 14s (- 18m 7s) (29100 58%) 0.0130\n",
      "25m 19s (- 18m 2s) (29200 58%) 0.0134\n",
      "25m 24s (- 17m 57s) (29300 58%) 0.0128\n",
      "25m 30s (- 17m 52s) (29400 58%) 0.0095\n",
      "25m 35s (- 17m 46s) (29500 59%) 0.0162\n",
      "25m 40s (- 17m 41s) (29600 59%) 0.0125\n",
      "25m 46s (- 17m 36s) (29700 59%) 0.0089\n",
      "25m 51s (- 17m 31s) (29800 59%) 0.0111\n",
      "25m 56s (- 17m 26s) (29900 59%) 0.0120\n",
      "26m 0s (- 17m 20s) (30000 60%) 0.0112\n",
      "26m 5s (- 17m 15s) (30100 60%) 0.0117\n",
      "26m 10s (- 17m 9s) (30200 60%) 0.0138\n",
      "26m 15s (- 17m 4s) (30300 60%) 0.0121\n",
      "26m 20s (- 16m 58s) (30400 60%) 0.0164\n",
      "26m 25s (- 16m 53s) (30500 61%) 0.0160\n",
      "26m 29s (- 16m 47s) (30600 61%) 0.0115\n",
      "26m 34s (- 16m 42s) (30700 61%) 0.0118\n",
      "26m 39s (- 16m 37s) (30800 61%) 0.0101\n",
      "26m 45s (- 16m 32s) (30900 61%) 0.0108\n",
      "26m 50s (- 16m 26s) (31000 62%) 0.0085\n",
      "26m 55s (- 16m 21s) (31100 62%) 0.0095\n",
      "27m 0s (- 16m 16s) (31200 62%) 0.0103\n",
      "27m 6s (- 16m 11s) (31300 62%) 0.0157\n",
      "27m 11s (- 16m 6s) (31400 62%) 0.0101\n",
      "27m 16s (- 16m 1s) (31500 63%) 0.0145\n",
      "27m 21s (- 15m 55s) (31600 63%) 0.0088\n",
      "27m 26s (- 15m 50s) (31700 63%) 0.0112\n",
      "27m 31s (- 15m 45s) (31800 63%) 0.0104\n",
      "27m 37s (- 15m 40s) (31900 63%) 0.0074\n",
      "27m 41s (- 15m 34s) (32000 64%) 0.0081\n",
      "27m 46s (- 15m 29s) (32100 64%) 0.0099\n",
      "27m 51s (- 15m 24s) (32200 64%) 0.0127\n",
      "27m 57s (- 15m 19s) (32300 64%) 0.0115\n",
      "28m 1s (- 15m 13s) (32400 64%) 0.0129\n",
      "28m 7s (- 15m 8s) (32500 65%) 0.0081\n",
      "28m 12s (- 15m 3s) (32600 65%) 0.0098\n",
      "28m 17s (- 14m 58s) (32700 65%) 0.0063\n",
      "28m 22s (- 14m 53s) (32800 65%) 0.0082\n",
      "28m 28s (- 14m 47s) (32900 65%) 0.0094\n",
      "28m 33s (- 14m 42s) (33000 66%) 0.0062\n",
      "28m 38s (- 14m 37s) (33100 66%) 0.0081\n",
      "28m 43s (- 14m 32s) (33200 66%) 0.0071\n",
      "28m 49s (- 14m 27s) (33300 66%) 0.0102\n",
      "28m 54s (- 14m 22s) (33400 66%) 0.0135\n",
      "28m 59s (- 14m 16s) (33500 67%) 0.0076\n",
      "29m 5s (- 14m 11s) (33600 67%) 0.0089\n",
      "29m 10s (- 14m 6s) (33700 67%) 0.0063\n",
      "29m 15s (- 14m 1s) (33800 67%) 0.0099\n",
      "29m 20s (- 13m 56s) (33900 67%) 0.0071\n",
      "29m 25s (- 13m 51s) (34000 68%) 0.0065\n",
      "29m 31s (- 13m 45s) (34100 68%) 0.0056\n",
      "29m 36s (- 13m 40s) (34200 68%) 0.0064\n",
      "29m 42s (- 13m 35s) (34300 68%) 0.0089\n",
      "29m 47s (- 13m 30s) (34400 68%) 0.0090\n",
      "29m 53s (- 13m 25s) (34500 69%) 0.0048\n",
      "29m 58s (- 13m 20s) (34600 69%) 0.0060\n",
      "30m 3s (- 13m 15s) (34700 69%) 0.0087\n",
      "30m 9s (- 13m 10s) (34800 69%) 0.0071\n",
      "30m 14s (- 13m 5s) (34900 69%) 0.0057\n",
      "30m 19s (- 12m 59s) (35000 70%) 0.0083\n",
      "30m 24s (- 12m 54s) (35100 70%) 0.0069\n",
      "30m 30s (- 12m 49s) (35200 70%) 0.0071\n",
      "30m 35s (- 12m 44s) (35300 70%) 0.0063\n",
      "30m 40s (- 12m 39s) (35400 70%) 0.0070\n",
      "30m 45s (- 12m 33s) (35500 71%) 0.0052\n",
      "30m 51s (- 12m 28s) (35600 71%) 0.0087\n",
      "30m 56s (- 12m 23s) (35700 71%) 0.0069\n",
      "31m 1s (- 12m 18s) (35800 71%) 0.0045\n",
      "31m 6s (- 12m 13s) (35900 71%) 0.0054\n",
      "31m 11s (- 12m 7s) (36000 72%) 0.0081\n",
      "31m 16s (- 12m 2s) (36100 72%) 0.0064\n",
      "31m 21s (- 11m 57s) (36200 72%) 0.0047\n",
      "31m 27s (- 11m 52s) (36300 72%) 0.0072\n",
      "31m 33s (- 11m 47s) (36400 72%) 0.0056\n",
      "31m 38s (- 11m 42s) (36500 73%) 0.0067\n",
      "31m 44s (- 11m 37s) (36600 73%) 0.0055\n",
      "31m 49s (- 11m 32s) (36700 73%) 0.0090\n",
      "31m 55s (- 11m 26s) (36800 73%) 0.0054\n",
      "32m 0s (- 11m 21s) (36900 73%) 0.0098\n",
      "32m 6s (- 11m 16s) (37000 74%) 0.0053\n",
      "32m 11s (- 11m 11s) (37100 74%) 0.0080\n",
      "32m 16s (- 11m 6s) (37200 74%) 0.0046\n",
      "32m 21s (- 11m 0s) (37300 74%) 0.0068\n",
      "32m 26s (- 10m 55s) (37400 74%) 0.0054\n",
      "32m 31s (- 10m 50s) (37500 75%) 0.0056\n",
      "32m 37s (- 10m 45s) (37600 75%) 0.0059\n",
      "32m 42s (- 10m 40s) (37700 75%) 0.0088\n",
      "32m 47s (- 10m 35s) (37800 75%) 0.0059\n",
      "32m 52s (- 10m 29s) (37900 75%) 0.0061\n",
      "32m 58s (- 10m 24s) (38000 76%) 0.0060\n",
      "33m 3s (- 10m 19s) (38100 76%) 0.0070\n",
      "33m 9s (- 10m 14s) (38200 76%) 0.0049\n",
      "33m 15s (- 10m 9s) (38300 76%) 0.0041\n",
      "33m 21s (- 10m 4s) (38400 76%) 0.0060\n",
      "33m 26s (- 9m 59s) (38500 77%) 0.0066\n",
      "33m 32s (- 9m 54s) (38600 77%) 0.0058\n",
      "33m 37s (- 9m 49s) (38700 77%) 0.0050\n",
      "33m 43s (- 9m 43s) (38800 77%) 0.0052\n",
      "33m 48s (- 9m 38s) (38900 77%) 0.0055\n",
      "33m 54s (- 9m 33s) (39000 78%) 0.0047\n",
      "33m 59s (- 9m 28s) (39100 78%) 0.0049\n",
      "34m 4s (- 9m 23s) (39200 78%) 0.0067\n",
      "34m 9s (- 9m 18s) (39300 78%) 0.0040\n",
      "34m 14s (- 9m 12s) (39400 78%) 0.0071\n",
      "34m 20s (- 9m 7s) (39500 79%) 0.0048\n",
      "34m 25s (- 9m 2s) (39600 79%) 0.0062\n",
      "34m 31s (- 8m 57s) (39700 79%) 0.0066\n",
      "34m 37s (- 8m 52s) (39800 79%) 0.0052\n",
      "34m 43s (- 8m 47s) (39900 79%) 0.0070\n",
      "34m 49s (- 8m 42s) (40000 80%) 0.0057\n",
      "34m 55s (- 8m 37s) (40100 80%) 0.0040\n",
      "35m 0s (- 8m 32s) (40200 80%) 0.0044\n",
      "35m 6s (- 8m 27s) (40300 80%) 0.0052\n",
      "35m 11s (- 8m 21s) (40400 80%) 0.0052\n",
      "35m 17s (- 8m 16s) (40500 81%) 0.0065\n",
      "35m 22s (- 8m 11s) (40600 81%) 0.0043\n",
      "35m 27s (- 8m 6s) (40700 81%) 0.0051\n",
      "35m 32s (- 8m 0s) (40800 81%) 0.0050\n",
      "35m 38s (- 7m 55s) (40900 81%) 0.0042\n",
      "35m 43s (- 7m 50s) (41000 82%) 0.0044\n",
      "35m 48s (- 7m 45s) (41100 82%) 0.0049\n",
      "35m 53s (- 7m 40s) (41200 82%) 0.0046\n",
      "35m 58s (- 7m 34s) (41300 82%) 0.0048\n",
      "36m 4s (- 7m 29s) (41400 82%) 0.0038\n",
      "36m 9s (- 7m 24s) (41500 83%) 0.0051\n",
      "36m 14s (- 7m 19s) (41600 83%) 0.0056\n",
      "36m 20s (- 7m 13s) (41700 83%) 0.0040\n",
      "36m 25s (- 7m 8s) (41800 83%) 0.0047\n",
      "36m 31s (- 7m 3s) (41900 83%) 0.0058\n",
      "36m 36s (- 6m 58s) (42000 84%) 0.0046\n",
      "36m 41s (- 6m 53s) (42100 84%) 0.0044\n",
      "36m 46s (- 6m 47s) (42200 84%) 0.0042\n",
      "36m 52s (- 6m 42s) (42300 84%) 0.0034\n",
      "36m 57s (- 6m 37s) (42400 84%) 0.0047\n",
      "37m 2s (- 6m 32s) (42500 85%) 0.0032\n",
      "37m 8s (- 6m 27s) (42600 85%) 0.0035\n",
      "37m 13s (- 6m 21s) (42700 85%) 0.0046\n",
      "37m 18s (- 6m 16s) (42800 85%) 0.0045\n",
      "37m 23s (- 6m 11s) (42900 85%) 0.0038\n",
      "37m 29s (- 6m 6s) (43000 86%) 0.0035\n",
      "37m 34s (- 6m 0s) (43100 86%) 0.0046\n",
      "37m 39s (- 5m 55s) (43200 86%) 0.0034\n",
      "37m 45s (- 5m 50s) (43300 86%) 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37m 50s (- 5m 45s) (43400 86%) 0.0057\n",
      "37m 55s (- 5m 40s) (43500 87%) 0.0041\n",
      "38m 1s (- 5m 34s) (43600 87%) 0.0026\n",
      "38m 6s (- 5m 29s) (43700 87%) 0.0039\n",
      "38m 11s (- 5m 24s) (43800 87%) 0.0026\n",
      "38m 17s (- 5m 19s) (43900 87%) 0.0039\n",
      "38m 22s (- 5m 13s) (44000 88%) 0.0040\n",
      "38m 27s (- 5m 8s) (44100 88%) 0.0035\n",
      "38m 32s (- 5m 3s) (44200 88%) 0.0041\n",
      "38m 38s (- 4m 58s) (44300 88%) 0.0042\n",
      "38m 43s (- 4m 53s) (44400 88%) 0.0029\n",
      "38m 48s (- 4m 47s) (44500 89%) 0.0029\n",
      "38m 54s (- 4m 42s) (44600 89%) 0.0031\n",
      "38m 59s (- 4m 37s) (44700 89%) 0.0039\n",
      "39m 4s (- 4m 32s) (44800 89%) 0.0046\n",
      "39m 10s (- 4m 26s) (44900 89%) 0.0045\n",
      "39m 15s (- 4m 21s) (45000 90%) 0.0030\n",
      "39m 20s (- 4m 16s) (45100 90%) 0.0038\n",
      "39m 25s (- 4m 11s) (45200 90%) 0.0032\n",
      "39m 31s (- 4m 6s) (45300 90%) 0.0041\n",
      "39m 36s (- 4m 0s) (45400 90%) 0.0035\n",
      "39m 41s (- 3m 55s) (45500 91%) 0.0034\n",
      "39m 47s (- 3m 50s) (45600 91%) 0.0037\n",
      "39m 52s (- 3m 45s) (45700 91%) 0.0032\n",
      "39m 57s (- 3m 39s) (45800 91%) 0.0030\n",
      "40m 3s (- 3m 34s) (45900 91%) 0.0029\n",
      "40m 8s (- 3m 29s) (46000 92%) 0.0029\n",
      "40m 13s (- 3m 24s) (46100 92%) 0.0028\n",
      "40m 19s (- 3m 18s) (46200 92%) 0.0032\n",
      "40m 24s (- 3m 13s) (46300 92%) 0.0040\n",
      "40m 29s (- 3m 8s) (46400 92%) 0.0028\n",
      "40m 35s (- 3m 3s) (46500 93%) 0.0033\n",
      "40m 40s (- 2m 58s) (46600 93%) 0.0048\n",
      "40m 45s (- 2m 52s) (46700 93%) 0.0039\n",
      "40m 50s (- 2m 47s) (46800 93%) 0.0025\n",
      "40m 55s (- 2m 42s) (46900 93%) 0.0034\n",
      "41m 0s (- 2m 37s) (47000 94%) 0.0031\n",
      "41m 5s (- 2m 31s) (47100 94%) 0.0033\n",
      "41m 10s (- 2m 26s) (47200 94%) 0.0040\n",
      "41m 16s (- 2m 21s) (47300 94%) 0.0028\n",
      "41m 21s (- 2m 16s) (47400 94%) 0.0036\n",
      "41m 26s (- 2m 10s) (47500 95%) 0.0033\n",
      "41m 31s (- 2m 5s) (47600 95%) 0.0044\n",
      "41m 36s (- 2m 0s) (47700 95%) 0.0036\n",
      "41m 42s (- 1m 55s) (47800 95%) 0.0049\n",
      "41m 47s (- 1m 49s) (47900 95%) 0.0055\n",
      "41m 52s (- 1m 44s) (48000 96%) 0.0033\n",
      "41m 58s (- 1m 39s) (48100 96%) 0.0036\n",
      "42m 3s (- 1m 34s) (48200 96%) 0.0046\n",
      "42m 8s (- 1m 29s) (48300 96%) 0.0028\n",
      "42m 13s (- 1m 23s) (48400 96%) 0.0045\n",
      "42m 18s (- 1m 18s) (48500 97%) 0.0033\n",
      "42m 23s (- 1m 13s) (48600 97%) 0.0034\n",
      "42m 28s (- 1m 8s) (48700 97%) 0.0036\n",
      "42m 33s (- 1m 2s) (48800 97%) 0.0030\n",
      "42m 39s (- 0m 57s) (48900 97%) 0.0029\n",
      "42m 44s (- 0m 52s) (49000 98%) 0.0030\n",
      "42m 49s (- 0m 47s) (49100 98%) 0.0026\n",
      "42m 54s (- 0m 41s) (49200 98%) 0.0029\n",
      "43m 0s (- 0m 36s) (49300 98%) 0.0040\n",
      "43m 5s (- 0m 31s) (49400 98%) 0.0032\n",
      "43m 10s (- 0m 26s) (49500 99%) 0.0025\n",
      "43m 15s (- 0m 20s) (49600 99%) 0.0036\n",
      "43m 21s (- 0m 15s) (49700 99%) 0.0046\n",
      "43m 26s (- 0m 10s) (49800 99%) 0.0054\n",
      "43m 31s (- 0m 5s) (49900 99%) 0.0027\n",
      "43m 37s (- 0m 0s) (50000 100%) 0.0034\n"
     ]
    }
   ],
   "source": [
    "encoder1 = EncoderLSTM(encoder_vocab_size, hidden_dim,embedding_size)\n",
    "decoder1 = DecoderDRNN(embedding_size,hidden_dim,decoder_vocab_size)\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda(gpu_no)\n",
    "    decoder1 = decoder1.cuda(gpu_no)\n",
    "\n",
    "trainIters(encoder1,decoder1, n_iters, training_pairs,print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the plot\n",
    "fig = plt.plot(list(range(len(plot_loss_avg))),plot_loss_avg)\n",
    "plt.ylabel('average loss values')\n",
    "plt.xlabel('number of training iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
