{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n",
      "[u'je realise un documentaire .', u'i m making a documentary .']\n"
     ]
    }
   ],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "            \n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, dropout=dropout_p)\n",
    "        self.out = nn.Linear(self.hidden_size * 2, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        energies = Variable(torch.zeros(len(encoder_outputs))).cuda()\n",
    "        for i in range(len(encoder_outputs)):\n",
    "            energies[i] = hidden.dot(encoder_outputs[i])\n",
    "        attention_weights = F.softmax(energies).unsqueeze(0).unsqueeze(0)   \n",
    "        \n",
    "        context = attention_weights.bmm(encoder_outputs.view(1,self.max_length,self.hidden_size))\n",
    "        \n",
    "        rnn_output = output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n",
    "        return output, hidden, attention_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        print iter\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 19s (- 97m 49s) (1000 1%) 3.4563\n",
      "2m 37s (- 95m 35s) (2000 2%) 2.9471\n",
      "3m 53s (- 93m 22s) (3000 4%) 2.6556\n",
      "5m 10s (- 91m 47s) (4000 5%) 2.4948\n",
      "6m 26s (- 90m 8s) (5000 6%) 2.4022\n",
      "7m 43s (- 88m 46s) (6000 8%) 2.2691\n",
      "9m 1s (- 87m 43s) (7000 9%) 2.1865\n",
      "10m 21s (- 86m 44s) (8000 10%) 2.1296\n",
      "11m 41s (- 85m 42s) (9000 12%) 2.1036\n",
      "13m 0s (- 84m 33s) (10000 13%) 1.9647\n",
      "14m 19s (- 83m 19s) (11000 14%) 1.8396\n",
      "15m 37s (- 82m 0s) (12000 16%) 1.7612\n",
      "16m 54s (- 80m 36s) (13000 17%) 1.7166\n",
      "18m 11s (- 79m 15s) (14000 18%) 1.6802\n",
      "19m 28s (- 77m 53s) (15000 20%) 1.6058\n",
      "20m 45s (- 76m 34s) (16000 21%) 1.6320\n",
      "22m 3s (- 75m 13s) (17000 22%) 1.5732\n",
      "23m 21s (- 73m 56s) (18000 24%) 1.5437\n",
      "24m 39s (- 72m 41s) (19000 25%) 1.4586\n",
      "25m 57s (- 71m 22s) (20000 26%) 1.4299\n",
      "27m 15s (- 70m 4s) (21000 28%) 1.4222\n",
      "28m 33s (- 68m 48s) (22000 29%) 1.3987\n",
      "29m 51s (- 67m 29s) (23000 30%) 1.1934\n",
      "31m 9s (- 66m 11s) (24000 32%) 1.2903\n",
      "32m 27s (- 64m 54s) (25000 33%) 1.2467\n",
      "33m 44s (- 63m 34s) (26000 34%) 1.2027\n",
      "35m 1s (- 62m 15s) (27000 36%) 1.1296\n",
      "36m 20s (- 60m 59s) (28000 37%) 1.1559\n",
      "37m 38s (- 59m 42s) (29000 38%) 1.0355\n",
      "38m 56s (- 58m 24s) (30000 40%) 1.0551\n",
      "40m 15s (- 57m 8s) (31000 41%) 1.0328\n",
      "41m 33s (- 55m 50s) (32000 42%) 0.9911\n",
      "42m 49s (- 54m 30s) (33000 44%) 1.0041\n",
      "44m 6s (- 53m 11s) (34000 45%) 1.0090\n",
      "45m 23s (- 51m 52s) (35000 46%) 0.9212\n",
      "46m 41s (- 50m 34s) (36000 48%) 0.9089\n",
      "47m 58s (- 49m 16s) (37000 49%) 0.8939\n",
      "49m 16s (- 47m 58s) (38000 50%) 0.9181\n",
      "50m 34s (- 46m 40s) (39000 52%) 0.8595\n",
      "51m 51s (- 45m 22s) (40000 53%) 0.8286\n",
      "53m 8s (- 44m 4s) (41000 54%) 0.7622\n",
      "54m 26s (- 42m 46s) (42000 56%) 0.8126\n",
      "55m 45s (- 41m 29s) (43000 57%) 0.7990\n",
      "57m 4s (- 40m 12s) (44000 58%) 0.7384\n",
      "58m 23s (- 38m 55s) (45000 60%) 0.7465\n",
      "59m 41s (- 37m 38s) (46000 61%) 0.7527\n",
      "60m 59s (- 36m 20s) (47000 62%) 0.6919\n",
      "62m 17s (- 35m 2s) (48000 64%) 0.7045\n",
      "63m 36s (- 33m 45s) (49000 65%) 0.6767\n",
      "64m 54s (- 32m 27s) (50000 66%) 0.6797\n",
      "66m 11s (- 31m 8s) (51000 68%) 0.7070\n",
      "67m 28s (- 29m 50s) (52000 69%) 0.6581\n",
      "68m 46s (- 28m 32s) (53000 70%) 0.6399\n",
      "70m 5s (- 27m 15s) (54000 72%) 0.6316\n",
      "71m 23s (- 25m 57s) (55000 73%) 0.6090\n",
      "72m 41s (- 24m 39s) (56000 74%) 0.5821\n",
      "73m 58s (- 23m 21s) (57000 76%) 0.5652\n",
      "75m 17s (- 22m 4s) (58000 77%) 0.5877\n",
      "76m 35s (- 20m 46s) (59000 78%) 0.5906\n",
      "77m 53s (- 19m 28s) (60000 80%) 0.6077\n",
      "79m 12s (- 18m 10s) (61000 81%) 0.5642\n",
      "80m 31s (- 16m 53s) (62000 82%) 0.5893\n",
      "81m 50s (- 15m 35s) (63000 84%) 0.5523\n",
      "83m 9s (- 14m 17s) (64000 85%) 0.5057\n",
      "84m 29s (- 12m 59s) (65000 86%) 0.4953\n",
      "85m 48s (- 11m 42s) (66000 88%) 0.5402\n",
      "87m 8s (- 10m 24s) (67000 89%) 0.5011\n",
      "88m 27s (- 9m 6s) (68000 90%) 0.4641\n",
      "89m 46s (- 7m 48s) (69000 92%) 0.4843\n",
      "91m 6s (- 6m 30s) (70000 93%) 0.4544\n",
      "92m 25s (- 5m 12s) (71000 94%) 0.4753\n",
      "93m 44s (- 3m 54s) (72000 96%) 0.4432\n",
      "95m 3s (- 2m 36s) (73000 97%) 0.3986\n",
      "96m 22s (- 1m 18s) (74000 98%) 0.4478\n",
      "97m 41s (- 0m 0s) (75000 100%) 0.4205\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words)\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    decoder1 = decoder1.cuda()\n",
    "\n",
    "trainIters(encoder1,decoder1, 75000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden,decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden,encoder_outputs)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> nous sommes vraiment mariees .\n",
      "= we re really married .\n",
      "< we re really married . <EOS>\n",
      "\n",
      "> tu es si gentille !\n",
      "= you re so sweet .\n",
      "< you re so sweet . <EOS>\n",
      "\n",
      "> je suis trop vieille pour vous .\n",
      "= i m too old for you .\n",
      "< i m too old for you . <EOS>\n",
      "\n",
      "> tu es trop jeune pour voyager seule .\n",
      "= you are too young to travel alone .\n",
      "< you are too young to travel alone . <EOS>\n",
      "\n",
      "> elle est connue de tout le monde .\n",
      "= she is known to everyone .\n",
      "< she is known to the everybody . <EOS>\n",
      "\n",
      "> elle le fixa avec stupefaction .\n",
      "= she stared at him in astonishment .\n",
      "< she said in the astonishment . <EOS>\n",
      "\n",
      "> je suis un etranger ici .\n",
      "= i am a stranger here .\n",
      "< i m a stranger here . <EOS>\n",
      "\n",
      "> nous ne sommes pas seules .\n",
      "= we are not alone .\n",
      "< we re not alone . <EOS>\n",
      "\n",
      "> on te reclame au telephone .\n",
      "= you are wanted on the phone .\n",
      "< you are wanted on the phone . <EOS>\n",
      "\n",
      "> elle depend de son epoux .\n",
      "= she s dependent on her husband .\n",
      "< she s dependent on her husband . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
